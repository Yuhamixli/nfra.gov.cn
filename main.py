#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡‘èç›‘ç®¡æ€»å±€è¡Œæ”¿å¤„ç½šä¿¡æ¯çˆ¬è™« - ä¸»ç¨‹åº
æä¾›å‘½ä»¤è¡Œæ¥å£ï¼Œæ”¯æŒæµ‹è¯•ã€æ­£å¼çˆ¬å–ã€æ•°æ®åˆ†æã€å®šæ—¶ä»»åŠ¡ç­‰åŠŸèƒ½
"""

import argparse
import sys
import schedule
import time
from datetime import datetime, timedelta
import logging
from calendar import monthrange

import os

# æ£€æµ‹exeæ¨¡å¼å¹¶å¯¼å…¥ç›¸åº”é…ç½®
if os.environ.get('NFRA_EXE_MODE') == '1':
    # EXEæ¨¡å¼ï¼šä½¿ç”¨exeä¸“ç”¨é…ç½®
    from config_exe import SELENIUM_CONFIG, OUTPUT_CONFIG, BASE_URLS
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œåˆ›å»ºEXEæ¨¡å¼çš„RUN_MODESå’ŒSCHEDULE_CONFIG
    RUN_MODES = {
        'test': {
            'description': 'æµ‹è¯•æ¨¡å¼ - æ¯ç±»5æ¡è®°å½•',
            'max_pages_per_category': 1,
            'max_records_per_category': 5
        },
        'init': {
            'description': 'åˆå§‹åŒ–æ¨¡å¼ - 2025å¹´å…¨éƒ¨æ•°æ®',
            'max_pages_per_category': 50,
            'max_records_per_category': None
        },
        'monthly': {
            'description': 'æœˆåº¦æ›´æ–°æ¨¡å¼ - ä¸Šä¸ªæœˆæ•°æ®',
            'max_pages_per_category': 10,
            'max_records_per_category': None
        },
        'daily': {
            'description': 'æ¯æ—¥æ›´æ–°æ¨¡å¼ - æ˜¨å¤©æ•°æ®',
            'max_pages_per_category': 3,
            'max_records_per_category': None
        }
    }
    SCHEDULE_CONFIG = {'enabled': False}  # EXEæ¨¡å¼ä¸éœ€è¦å®šæ—¶ä»»åŠ¡
else:
    # æ­£å¸¸æ¨¡å¼ï¼šä½¿ç”¨æ ‡å‡†é…ç½®
    from config import SCHEDULE_CONFIG, OUTPUT_CONFIG, SELENIUM_CONFIG, RUN_MODES, BASE_URLS

from crawler import NFRACrawler
from data_processor import DataProcessor, process_and_save_data
from utils import setup_logging, load_existing_data, merge_data


def get_available_categories():
    """è·å–å¯ç”¨çš„çˆ¬å–ç±»åˆ«"""
    return list(BASE_URLS.keys())


def parse_categories(category_arg):
    """è§£æç±»åˆ«å‚æ•°"""
    available_categories = get_available_categories()
    
    if not category_arg:
        return available_categories  # é»˜è®¤çˆ¬å–æ‰€æœ‰ç±»åˆ«
    
    # æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼
    if category_arg == 'all':
        return available_categories
    
    # æ”¯æŒç®€å†™
    category_mapping = {
        'æ€»å±€': 'æ€»å±€æœºå…³',
        'zhongju': 'æ€»å±€æœºå…³',
        '1': 'æ€»å±€æœºå…³',
        
        'ç›‘ç®¡å±€': 'ç›‘ç®¡å±€æœ¬çº§',
        'jianguanju': 'ç›‘ç®¡å±€æœ¬çº§', 
        '2': 'ç›‘ç®¡å±€æœ¬çº§',
        
        'ç›‘ç®¡åˆ†å±€': 'ç›‘ç®¡åˆ†å±€æœ¬çº§',
        'fenju': 'ç›‘ç®¡åˆ†å±€æœ¬çº§',
        '3': 'ç›‘ç®¡åˆ†å±€æœ¬çº§'
    }
    
    # å¤„ç†é€—å·åˆ†éš”çš„å¤šä¸ªç±»åˆ«
    requested_categories = []
    for cat in category_arg.split(','):
        cat = cat.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´åç§°
        if cat in available_categories:
            requested_categories.append(cat)
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç®€å†™
        elif cat in category_mapping:
            requested_categories.append(category_mapping[cat])
        else:
            print(f"âš ï¸  è­¦å‘Šï¼šæœªçŸ¥ç±»åˆ« '{cat}'")
            print(f"å¯ç”¨ç±»åˆ«ï¼š{', '.join(available_categories)}")
            print(f"ç®€å†™æ–¹å¼ï¼šæ€»å±€/zhongju/1, ç›‘ç®¡å±€/jianguanju/2, ç›‘ç®¡åˆ†å±€/fenju/3, all")
    
    return requested_categories if requested_categories else available_categories


def run_crawl_by_mode(mode: str, categories: list = None) -> bool:
    """æ ¹æ®æ¨¡å¼æ‰§è¡Œçˆ¬å–ä»»åŠ¡"""
    logger = setup_logging()
    
    if mode not in RUN_MODES:
        logger.error(f"ä¸æ”¯æŒçš„è¿è¡Œæ¨¡å¼: {mode}")
        return False
    
    # ç¡®å®šè¦çˆ¬å–çš„ç±»åˆ«
    if categories is None:
        categories = get_available_categories()
    
    mode_config = RUN_MODES[mode]
    logger.info(f"å¼€å§‹æ‰§è¡Œ {mode_config['description']}...")
    logger.info(f"çˆ¬å–ç±»åˆ«: {', '.join(categories)}")
    
    try:
        crawler = NFRACrawler(headless=SELENIUM_CONFIG['headless'])
        
        # æ‰§è¡Œçˆ¬å–
        if mode == 'init':
            # åˆå§‹åŒ–æ¨¡å¼ï¼šæ™ºèƒ½è·å–2025å¹´çš„æ‰€æœ‰æ•°æ®
            logger.info("åˆå§‹åŒ–æ¨¡å¼ï¼šæ™ºèƒ½è·å–2025å¹´å…¨éƒ¨è¡Œæ”¿å¤„ç½šä¿¡æ¯...")
            
            # ä½¿ç”¨æ™ºèƒ½çˆ¬å–æ–¹æ³•ï¼ŒæŒ‰å¹´ä»½è¿‡æ»¤ï¼ŒæŒ‡å®šç±»åˆ«
            filtered_data = crawler.crawl_selected_categories_by_year(
                categories=categories,
                target_year=2025,
                max_pages_per_category=mode_config['max_pages_per_category'],
                max_records_per_category=mode_config['max_records_per_category']
            )
            
            total_records = sum(len(records) for records in filtered_data.values())
            logger.info(f"æ™ºèƒ½çˆ¬å–å®Œæˆï¼Œ2025å¹´å…±è·å¾—: {total_records} æ¡")
            
        elif mode == 'monthly':
            # æœˆåº¦æ›´æ–°æ¨¡å¼ï¼šæ™ºèƒ½è·å–ä¸Šä¸ªæœˆçš„æ•°æ®
            last_year, last_month = get_last_month()
            logger.info(f"æœˆåº¦æ›´æ–°æ¨¡å¼ï¼šæ™ºèƒ½è·å–{last_year}å¹´{last_month}æœˆå‘å¸ƒçš„æ•°æ®...")
            
            # ä½¿ç”¨æ™ºèƒ½çˆ¬å–æ–¹æ³•ï¼Œç›´æ¥è·å–ç›®æ ‡æœˆä»½çš„æ•°æ®ï¼ŒæŒ‡å®šç±»åˆ«
            filtered_data = crawler.crawl_selected_categories_by_month(
                categories=categories,
                target_year=last_year,
                target_month=last_month,
                max_pages_per_category=mode_config['max_pages_per_category'],
                max_records_per_category=mode_config['max_records_per_category'],
                use_smart_check=True  # å¯ç”¨æ™ºèƒ½æ—¥æœŸè¿‡æ»¤å’Œå€’åºä¼˜åŒ–
            )
            
            total_records = sum(len(records) for records in filtered_data.values())
            logger.info(f"æ™ºèƒ½çˆ¬å–å®Œæˆï¼Œ{last_year}å¹´{last_month}æœˆå…±è·å¾—: {total_records} æ¡")
            
        elif mode == 'daily':
            # æ¯æ—¥æ›´æ–°æ¨¡å¼ï¼šæ™ºèƒ½è·å–æ˜¨å¤©çš„æ•°æ®
            yesterday = datetime.now() - timedelta(days=1)
            target_year, target_month, target_day = yesterday.year, yesterday.month, yesterday.day
            logger.info(f"æ¯æ—¥æ›´æ–°æ¨¡å¼ï¼šæ™ºèƒ½è·å–{target_year}å¹´{target_month}æœˆ{target_day}æ—¥å‘å¸ƒçš„æ•°æ®...")
            
            # ä½¿ç”¨æ™ºèƒ½çˆ¬å–æ–¹æ³•ï¼Œè·å–æ˜¨å¤©çš„æ•°æ®ï¼ŒæŒ‡å®šç±»åˆ«
            filtered_data = crawler.crawl_selected_categories_by_date(
                categories=categories,
                target_year=target_year,
                target_month=target_month,
                target_day=target_day,
                max_pages_per_category=mode_config['max_pages_per_category'],
                max_records_per_category=mode_config['max_records_per_category']
            )
            
            total_records = sum(len(records) for records in filtered_data.values())
            logger.info(f"æ™ºèƒ½çˆ¬å–å®Œæˆï¼Œ{target_year}å¹´{target_month}æœˆ{target_day}æ—¥å…±è·å¾—: {total_records} æ¡")
            
        else:
            # å…¶ä»–æ¨¡å¼ - æ™®é€šçˆ¬å–æŒ‡å®šç±»åˆ«
            filtered_data = crawler.crawl_selected_categories(
                categories=categories,
                max_pages_per_category=mode_config['max_pages_per_category'],
                max_records_per_category=mode_config['max_records_per_category']
            )
        
        if filtered_data:
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            categories_str = '_'.join(categories) if len(categories) < len(get_available_categories()) else 'å…¨éƒ¨ç±»åˆ«'
            filename = f'excel_output/{mode}æ¨¡å¼_{categories_str}_{timestamp}.xlsx'
            
            # å¤„ç†å’Œä¿å­˜æ•°æ®
            success = process_and_save_data(
                filtered_data, 
                filename, 
                include_text_export=(mode == 'test')
            )
            
            if success:
                total_records = sum(len(records) for records in filtered_data.values())
                logger.info(f"{mode_config['description']}å®Œæˆï¼")
                logger.info(f"è·å¾— {total_records} æ¡è®°å½•ï¼Œä¿å­˜è‡³: {filename}")
                
                # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
                for category, records in filtered_data.items():
                    logger.info(f"  {category}: {len(records)} æ¡")
                
                return True
            else:
                logger.error("æ•°æ®å¤„ç†å¤±è´¥")
                return False
        else:
            logger.warning("æœªè·å–åˆ°æ•°æ®")
            return False
            
    except Exception as e:
        logger.error(f"{mode_config['description']}å¤±è´¥: {e}")
        return False


def filter_data_by_year(data: dict, target_year: int) -> dict:
    """è¿‡æ»¤æŒ‡å®šå¹´ä»½çš„æ•°æ®"""
    logger = logging.getLogger(__name__)
    filtered_data = {}
    
    for category, records in data.items():
        filtered_records = []
        
        for record in records:
            # æ£€æŸ¥å‘å¸ƒæ—¶é—´æˆ–æŠ“å–æ—¶é—´
            publish_time = record.get('å‘å¸ƒæ—¶é—´', '')
            crawl_time = record.get('æŠ“å–æ—¶é—´', '')
            
            # å°è¯•ä»å‘å¸ƒæ—¶é—´åˆ¤æ–­å¹´ä»½
            if publish_time and str(target_year) in str(publish_time):
                filtered_records.append(record)
            # å¦‚æœå‘å¸ƒæ—¶é—´ä¸æ˜ç¡®ï¼Œæ£€æŸ¥æŠ“å–æ—¶é—´
            elif crawl_time and str(target_year) in str(crawl_time):
                filtered_records.append(record)
            # å¦‚æœéƒ½æ²¡æœ‰æ˜ç¡®æ—¶é—´ï¼Œä¿ç•™è®°å½•ï¼ˆé¿å…æ¼æ‰ï¼‰
            elif not publish_time and not crawl_time:
                filtered_records.append(record)
        
        if filtered_records:
            filtered_data[category] = filtered_records
            logger.info(f"{category}: è¿‡æ»¤åˆ° {len(filtered_records)} æ¡{target_year}å¹´è®°å½•")
    
    return filtered_data


def filter_data_by_month(data: dict, target_year: int, target_month: int) -> dict:
    """è¿‡æ»¤æŒ‡å®šå¹´æœˆçš„æ•°æ®"""
    logger = logging.getLogger(__name__)
    filtered_data = {}
    
    # æ„å»ºç›®æ ‡æœˆä»½çš„æ—¥æœŸèŒƒå›´
    # è·å–ç›®æ ‡æœˆä»½çš„ç¬¬ä¸€å¤©å’Œæœ€åä¸€å¤©
    first_day = f"{target_year}-{target_month:02d}-01"
    last_day_num = monthrange(target_year, target_month)[1]
    last_day = f"{target_year}-{target_month:02d}-{last_day_num:02d}"
    
    logger.info(f"è¿‡æ»¤ {target_year}å¹´{target_month}æœˆ ({first_day} è‡³ {last_day}) çš„æ•°æ®")
    
    for category, records in data.items():
        filtered_records = []
        
        for record in records:
            # æ£€æŸ¥å‘å¸ƒæ—¶é—´
            publish_time = record.get('å‘å¸ƒæ—¶é—´', '')
            crawl_time = record.get('æŠ“å–æ—¶é—´', '')
            
            # ä¼˜å…ˆä½¿ç”¨å‘å¸ƒæ—¶é—´
            time_to_check = publish_time or crawl_time
            
            if time_to_check:
                try:
                    # å°è¯•è§£ææ—¶é—´
                    if isinstance(time_to_check, str):
                        # å¤„ç†å¤šç§æ—¶é—´æ ¼å¼
                        parsed_time = None
                        for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']:
                            try:
                                parsed_time = datetime.strptime(time_to_check, fmt)
                                break
                            except ValueError:
                                continue
                        
                        if parsed_time:
                            # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡æœˆä»½å†…
                            if (parsed_time.year == target_year and 
                                parsed_time.month == target_month):
                                filtered_records.append(record)
                        else:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å­—ç¬¦ä¸²åŒ¹é…
                            month_str = f"{target_year}-{target_month:02d}"
                            if month_str in str(time_to_check):
                                filtered_records.append(record)
                    else:
                        # å¦‚æœæ˜¯datetimeå¯¹è±¡
                        if (time_to_check.year == target_year and 
                            time_to_check.month == target_month):
                            filtered_records.append(record)
                except Exception as e:
                    logger.debug(f"æ—¶é—´è§£æå¤±è´¥: {time_to_check}, é”™è¯¯: {e}")
                    # è§£æå¤±è´¥æ—¶ï¼Œå°è¯•å­—ç¬¦ä¸²åŒ¹é…ä½œä¸ºåå¤‡
                    month_str = f"{target_year}-{target_month:02d}"
                    if month_str in str(time_to_check):
                        filtered_records.append(record)
            else:
                # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œä¸åŒ…å«è¯¥è®°å½•
                logger.debug("è®°å½•ç¼ºå°‘æ—¶é—´ä¿¡æ¯ï¼Œè·³è¿‡")
        
        if filtered_records:
            filtered_data[category] = filtered_records
            logger.info(f"{category}: è¿‡æ»¤åˆ° {len(filtered_records)} æ¡{target_year}å¹´{target_month}æœˆè®°å½•")
    
    return filtered_data


def get_last_month() -> tuple:
    """è·å–ä¸Šä¸ªæœˆçš„å¹´ä»½å’Œæœˆä»½"""
    today = datetime.now()
    if today.month == 1:
        return today.year - 1, 12
    else:
        return today.year, today.month - 1


def filter_data_by_days(data: dict, days: int) -> dict:
    """è¿‡æ»¤æœ€è¿‘Nå¤©çš„æ•°æ®"""
    logger = logging.getLogger(__name__)
    cutoff_date = datetime.now() - timedelta(days=days)
    filtered_data = {}
    
    for category, records in data.items():
        filtered_records = []
        
        for record in records:
            # æ£€æŸ¥å‘å¸ƒæ—¶é—´
            publish_time = record.get('å‘å¸ƒæ—¶é—´', '')
            if publish_time:
                try:
                    # å°è¯•è§£ææ—¶é—´
                    if isinstance(publish_time, str):
                        # å¤„ç†å¤šç§æ—¶é—´æ ¼å¼
                        for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d', '%Y/%m/%d']:
                            try:
                                parsed_time = datetime.strptime(publish_time, fmt)
                                if parsed_time >= cutoff_date:
                                    filtered_records.append(record)
                                break
                            except ValueError:
                                continue
                    else:
                        # å¦‚æœæ˜¯datetimeå¯¹è±¡
                        if publish_time >= cutoff_date:
                            filtered_records.append(record)
                except Exception:
                    # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™è®°å½•ï¼ˆé¿å…æ¼æ‰ï¼‰
                    filtered_records.append(record)
            else:
                # å¦‚æœæ²¡æœ‰å‘å¸ƒæ—¶é—´ï¼Œä¿ç•™è®°å½•
                filtered_records.append(record)
        
        if filtered_records:
            filtered_data[category] = filtered_records
            logger.info(f"{category}: è¿‡æ»¤åˆ° {len(filtered_records)} æ¡æœ€è¿‘{days}å¤©è®°å½•")
    
    return filtered_data


def run_test_crawl():
    """æ‰§è¡Œæµ‹è¯•çˆ¬å–"""
    return run_crawl_by_mode('test')


def run_init_crawl():
    """æ‰§è¡Œåˆå§‹åŒ–çˆ¬å– - ä¸‹è½½2025å¹´å…¨éƒ¨æ•°æ®"""
    return run_crawl_by_mode('init')


def run_monthly_update():
    """æ‰§è¡Œæœˆåº¦æ›´æ–° - è·å–æœ€æ–°æ•°æ®"""
    return run_crawl_by_mode('monthly')


def run_daily_update():
    """æ‰§è¡Œæ¯æ—¥æ›´æ–° - è·å–æ˜¨å¤©å‘å¸ƒçš„æ•°æ®"""
    return run_crawl_by_mode('daily')


def run_full_crawl():
    """æ‰§è¡Œå®Œæ•´çˆ¬å– - è·å–æ‰€æœ‰æ•°æ®"""
    return run_crawl_by_mode('full')


def run_scheduled_crawl():
    """è¿è¡Œå®šæ—¶çˆ¬å–"""
    logger = setup_logging()
    logger.info("å¯åŠ¨å®šæ—¶çˆ¬å–æœåŠ¡")
    logger.info(f"è®¡åˆ’æ‰§è¡Œæ—¶é—´: æ¯å¤© {SCHEDULE_CONFIG['update_time']}")
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡
    schedule.every().day.at(SCHEDULE_CONFIG['update_time']).do(
        lambda: run_crawl_by_mode('full')  # å®šæ—¶ä»»åŠ¡çˆ¬å–æ›´å¤šé¡µé¢
    )
    
    logger.info("å®šæ—¶ä»»åŠ¡å·²è®¾ç½®ï¼Œç­‰å¾…æ‰§è¡Œ...")
    logger.info("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢å®šæ—¶ä»»åŠ¡")
    except Exception as e:
        logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")


def run_data_analysis():
    """è¿è¡Œæ•°æ®åˆ†æ"""
    logger = setup_logging()
    logger.info("å¼€å§‹æ•°æ®åˆ†æ...")
    
    try:
        # åŠ è½½ç°æœ‰æ•°æ®
        existing_data = load_existing_data()
        
        if not any(existing_data.values()):
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç°æœ‰æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œçˆ¬å–ä»»åŠ¡")
            return False
        
        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = DataProcessor()
        
        # æ•°æ®è´¨é‡åˆ†æ
        quality_report = processor.validate_data_quality(existing_data)
        
        logger.info("=" * 40)
        logger.info("æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š")
        logger.info("=" * 40)
        logger.info(f"æ€»è®¡è®°å½•æ•°: {quality_report['total_records']}")
        
        for category, stats in quality_report['categories'].items():
            logger.info(f"\n{category}:")
            logger.info(f"  æ€»è®°å½•æ•°: {stats['total']}")
            logger.info(f"  æœ‰æ•ˆè®°å½•: {stats['valid_records']}")
            logger.info(f"  ç¼ºå°‘å½“äº‹äºº: {stats['missing_name']}")
            logger.info(f"  ç¼ºå°‘å¤„ç½šå†…å®¹: {stats['missing_punishment']}")
            logger.info(f"  ç¼ºå°‘å†³å®šæœºå…³: {stats['missing_authority']}")
        
        if quality_report['issues']:
            logger.info(f"\nå‘ç°çš„é—®é¢˜:")
            for issue in quality_report['issues']:
                logger.info(f"  - {issue}")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        analysis_filename = f'excel_output/æ•°æ®åˆ†ææŠ¥å‘Š_{timestamp}.xlsx'
        
        success = processor.generate_excel_report(existing_data, analysis_filename)
        
        if success:
            logger.info(f"\nåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {analysis_filename}")
            return True
        else:
            logger.error("ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œç•Œé¢"""
    parser = argparse.ArgumentParser(description='é‡‘èç›‘ç®¡æ€»å±€è¡Œæ”¿å¤„ç½šä¿¡æ¯çˆ¬è™«')
    parser.add_argument('command', 
                       choices=['test', 'init', 'monthly', 'daily', 'run', 'analysis', 'schedule'], 
                       help='æ‰§è¡Œå‘½ä»¤')
    parser.add_argument('--pages', type=int, default=5, help='æ¯ä¸ªåˆ†ç±»çˆ¬å–çš„æœ€å¤§é¡µæ•°')
    parser.add_argument('--text', action='store_true', help='åŒæ—¶å¯¼å‡ºæ–‡æœ¬æ–‡ä»¶')
    parser.add_argument('--categories', help='çˆ¬å–çš„ç±»åˆ«ï¼Œå¤šä¸ªç±»åˆ«ç”¨é€—å·åˆ†éš”')
    
    args = parser.parse_args()
    
    # è§£æç±»åˆ«å‚æ•°
    categories = parse_categories(args.categories)
    if args.categories:
        print(f"ğŸ¯ æŒ‡å®šçˆ¬å–ç±»åˆ«: {', '.join(categories)}")
    
    try:
        if args.command == 'test':
            print("æµ‹è¯•æ¨¡å¼ï¼ˆçˆ¬å–ç¬¬ä¸€é¡µæ•°æ®ï¼‰...")
            success = run_crawl_by_mode('test', categories)
            
        elif args.command == 'init':
            print("åˆå§‹åŒ–æ¨¡å¼ï¼ˆä¸‹è½½2025å¹´å…¨éƒ¨æ•°æ®ï¼‰...")
            print("âš ï¸  æ³¨æ„ï¼šæ­¤æ¨¡å¼å°†çˆ¬å–å¤§é‡æ•°æ®ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼")
            confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
            if confirm.lower() == 'y':
                success = run_crawl_by_mode('init', categories)
            else:
                print("å·²å–æ¶ˆåˆå§‹åŒ–ã€‚")
                return
                
        elif args.command == 'monthly':
            # æ˜¾ç¤ºå°†è¦çˆ¬å–çš„æœˆä»½ä¿¡æ¯
            last_year, last_month = get_last_month()
            print(f"æœˆåº¦æ›´æ–°æ¨¡å¼ï¼ˆè·å–{last_year}å¹´{last_month}æœˆæ•°æ®ï¼‰...")
            print(f"ğŸ“… ç›®æ ‡æœˆä»½ï¼š{last_year}å¹´{last_month}æœˆ")
            print(f"â±ï¸  é¢„è®¡è€—æ—¶ï¼š10-20åˆ†é’Ÿ")
            success = run_crawl_by_mode('monthly', categories)
            
        elif args.command == 'daily':
            print("æ¯æ—¥æ›´æ–°æ¨¡å¼ï¼ˆè·å–æ˜¨å¤©å‘å¸ƒçš„æ•°æ®ï¼‰...")
            success = run_crawl_by_mode('daily', categories)
            
        elif args.command == 'run':
            print("å®Œæ•´çˆ¬å–æ¨¡å¼...")
            if args.text:
                print("åŒæ—¶å¯¼å‡ºæ–‡æœ¬æ–‡ä»¶...")
            
            categories = parse_categories(args.categories)
            success = run_crawl_by_mode('full', categories)
            
        elif args.command == 'analysis':
            print("æ•°æ®åˆ†ææ¨¡å¼...")
            success = run_data_analysis()
            
        elif args.command == 'schedule':
            print("å¯åŠ¨å®šæ—¶ä»»åŠ¡...")
            run_scheduled_crawl()
            return  # å®šæ—¶ä»»åŠ¡ä¸éœ€è¦successæ£€æŸ¥
            
        else:
            parser.print_help()
            return
        
        if success:
            print("ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
        else:
            print("ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


def print_help():
    """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
    print("""
é‡‘èç›‘ç®¡æ€»å±€è¡Œæ”¿å¤„ç½šä¿¡æ¯çˆ¬è™«

ä½¿ç”¨æ–¹æ³•:
    python main.py run [--categories=ç±»åˆ«]     æ‰§è¡Œçˆ¬å–
    python main.py test [--categories=ç±»åˆ«]    æµ‹è¯•æ¨¡å¼
    python main.py monthly [--categories=ç±»åˆ«] æœˆåº¦æ›´æ–°
    python main.py init [--categories=ç±»åˆ«]    åˆå§‹åŒ–
    python main.py daily [--categories=ç±»åˆ«]   æ¯æ—¥æ›´æ–°
    python main.py schedule                    å¯åŠ¨å®šæ—¶çˆ¬å–æœåŠ¡
    python main.py analysis                    åˆ†æç°æœ‰æ•°æ®

å‚æ•°è¯´æ˜:
    --categories  æŒ‡å®šçˆ¬å–ç±»åˆ«ï¼Œå¤šä¸ªç±»åˆ«ç”¨é€—å·åˆ†éš”
                  å¯ç”¨ç±»åˆ«ï¼šæ€»å±€æœºå…³, ç›‘ç®¡å±€æœ¬çº§, ç›‘ç®¡åˆ†å±€æœ¬çº§
                  ç®€å†™æ–¹å¼ï¼šæ€»å±€/zhongju/1, ç›‘ç®¡å±€/jianguanju/2, ç›‘ç®¡åˆ†å±€/fenju/3, all
    --pages       æ¯ä¸ªåˆ†ç±»çˆ¬å–çš„æœ€å¤§é¡µæ•°ï¼Œé»˜è®¤5é¡µ
    --text        åŒæ—¶å¯¼å‡ºæ–‡æœ¬æ–‡ä»¶

ç¤ºä¾‹:
    python main.py monthly                              # çˆ¬å–æ‰€æœ‰ç±»åˆ«çš„ä¸Šæœˆæ•°æ®
    python main.py monthly --categories=æ€»å±€            # åªçˆ¬å–æ€»å±€æœºå…³çš„ä¸Šæœˆæ•°æ®
    python main.py test --categories=æ€»å±€,ç›‘ç®¡å±€        # æµ‹è¯•æ€»å±€æœºå…³å’Œç›‘ç®¡å±€æœ¬çº§
    python main.py run --categories=1,2                # çˆ¬å–æ€»å±€æœºå…³å’Œç›‘ç®¡å±€æœ¬çº§
    python main.py init --categories=fenju             # åˆå§‹åŒ–ç›‘ç®¡åˆ†å±€æœ¬çº§æ•°æ®

ç±»åˆ«è¯´æ˜:
    æ€»å±€æœºå…³     - å›½å®¶é‡‘èç›‘ç£ç®¡ç†æ€»å±€æœºå…³å‘å¸ƒçš„å¤„ç½šä¿¡æ¯
    ç›‘ç®¡å±€æœ¬çº§   - å„åœ°ç›‘ç®¡å±€æœ¬çº§å‘å¸ƒçš„å¤„ç½šä¿¡æ¯  
    ç›‘ç®¡åˆ†å±€æœ¬çº§ - å„åœ°ç›‘ç®¡åˆ†å±€æœ¬çº§å‘å¸ƒçš„å¤„ç½šä¿¡æ¯

è¯´æ˜:
    - çˆ¬å–çš„æ•°æ®ä¿å­˜åˆ°Excelæ–‡ä»¶ä¸­ï¼ŒæŒ‰åˆ†ç±»æ•´ç†
    - æ”¯æŒæ™ºèƒ½è¿‡æ»¤ï¼Œæœˆåº¦æ¨¡å¼åªçˆ¬å–ç›®æ ‡æœˆä»½æ•°æ®
    - è‡ªåŠ¨å¤‡ä»½å†å²æ•°æ®ï¼Œè¯¦ç»†æ—¥å¿—è®°å½•åœ¨ crawl.log æ–‡ä»¶ä¸­
    - åŒ…å«æ•°æ®è´¨é‡æ£€æŸ¥å’Œåˆ†æåŠŸèƒ½
    """)


if __name__ == "__main__":
    main() 